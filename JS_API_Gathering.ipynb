{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_api_key = open('./../../API_keys/youtube.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube API key is valid.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Function to test if the YouTube API key is valid\n",
    "def is_youtube_api_key_valid(api_key):\n",
    "    url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "    params = {\n",
    "        'part': 'snippet',\n",
    "        'chart': 'mostPopular',\n",
    "        'regionCode': 'US',\n",
    "        'key': api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    return response#.status_code == 200\n",
    "\n",
    "# Usage\n",
    "#youtube_api_key = 'YOUR_YOUTUBE_API_KEY'\n",
    "if is_youtube_api_key_valid(youtube_api_key):\n",
    "    print(\"YouTube API key is valid.\")\n",
    "else:\n",
    "    print(\"YouTube API key is invalid or expired.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_youtube_api_key_valid(youtube_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_video_ids(api_key, channel_id):\n",
    "    url = \"https://www.googleapis.com/youtube/v3/search\"\n",
    "    video_ids = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            'part': 'id',\n",
    "            'channelId': channel_id,\n",
    "            'maxResults': 50,\n",
    "            'pageToken': next_page_token,\n",
    "            'type': 'video',\n",
    "            'key': api_key\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params).json()\n",
    "\n",
    "        video_ids += [item['id']['videoId'] for item in response.get('items', [])]\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return video_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_title(video_id, api_key):\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videos?id={video_id}&key={api_key}&part=snippet\"\n",
    "    response = requests.get(url).json()\n",
    "    title = response['items'][0]['snippet']['title']\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['W84ws9AazSc', 'VNvH3a6Aenw', '4wi49P-Qjcc', 'XoUR_PQIdRg', '0Vijus_c-aY']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_video_IDs = get_video_ids(youtube_api_key, \"UCv4VkfbX8YfqodF-4coEEfQ\")\n",
    "print(len(list_video_IDs))\n",
    "list_video_IDs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-transcript-api\n",
      "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\peridot of earth\\anaconda3\\lib\\site-packages (from youtube-transcript-api) (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\peridot of earth\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\peridot of earth\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (2023.5.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\peridot of earth\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\peridot of earth\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (3.0.4)\n",
      "Installing collected packages: youtube-transcript-api\n",
      "Successfully installed youtube-transcript-api-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound\n",
    "\n",
    "def get_transcript(video_id):\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return \" \".join([item['text'] for item in transcript_list])\n",
    "    except NoTranscriptFound:\n",
    "        return \"No transcript found\"\n",
    "\n",
    "# Example Usage\n",
    "# video_ids = get_video_ids(your_api_key, channel_id)\n",
    "# for video_id in video_ids:\n",
    "#     print(get_transcript(video_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcript for video: 'H65WG2s4pzY' was unavailable\n"
     ]
    }
   ],
   "source": [
    "dict_transcripts_two = {}\n",
    "\n",
    "for str_video_id in list_video_IDs:\n",
    "    try:\n",
    "        dict_transcripts_two[str_video_id] = get_transcript(str_video_id)\n",
    "    except:\n",
    "        print(\"transcript for video: '\" + str_video_id + \"' was unavailable\")\n",
    "\n",
    "# video_transcripts now contains a dictionary where keys are video IDs and values are transcripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info for video: 'H65WG2s4pzY' was unavailable\n"
     ]
    }
   ],
   "source": [
    "dict_transcripts_two = {}\n",
    "\n",
    "for str_video_id in list_video_IDs:\n",
    "    try:\n",
    "        dict_transcripts_two[str_video_id] = {'title': get_video_title(str_video_id, youtube_api_key), \n",
    "                                          'transcript': get_transcript(str_video_id)}\n",
    "    except:\n",
    "        print(\"Info for video: '\" + str_video_id + \"' was unavailable\")\n",
    "\n",
    "# video_transcripts now contains a dictionary where keys are video IDs and values are transcripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_transcripts_two))\n",
    "#dict_transcripts_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_transcripts))\n",
    "#dict_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-40-ad41afd879e8>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-40-ad41afd879e8>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    #print(video_id, \"BLAH\", details)\u001b[0m\n\u001b[1;37m                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for video_id, details in dict_transcripts_two.items():\n",
    "    #print(video_id, \"BLAH\", details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for video_id, details in dict_transcripts_two.items():\n",
    "    title = details['title']\n",
    "    transcript = details['transcript']\n",
    "    \n",
    "    # Replace characters not allowed in file names\n",
    "    filename = \"\".join([c for c in title if c.isalpha() or c.isdigit() or c==' ']).rstrip()\n",
    "    \n",
    "    # Limiting filename length to avoid errors on some file systems\n",
    "    filename = filename[:100] if len(filename) > 100 else filename\n",
    "\n",
    "    # Writing to file\n",
    "    with open(f\"./data/{filename}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-43-ba632ff038f0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-43-ba632ff038f0>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for video_id, deets in dict_transcripts_two.items():\u001b[0m\n\u001b[1;37m                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for video_id, deets in dict_transcripts_two.items():\n",
    "    deetslen(deets[\"transcript\"].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 Neil Gaiman: A straight author with amazing queer characters?\n",
      "136 The Real Burden of Being Rich\n",
      "4414 The Troubling Thirst for Jeffrey Dahmer\n",
      "3679 The Traumatic Camp of \"Mommie Dearest\"\n",
      "3462 The Secret Crimes of a Dying Franchise\n",
      "3956 The Gay Horror Manga You Should Be Reading\n",
      "4639 When Hollywood Came Out of the Closet\n",
      "4615 America v. Homosexuality\n",
      "4451 Where The \"Bury Your Gays\" Trope Came From\n",
      "4294 How a Gay Show Changed TV... and Was Forgotten\n",
      "4683 Hollywood's Golden Age (of Queer Coding)\n",
      "4937 How Hollywood was Born Gay\n",
      "10 Coming This Fall\n",
      "35 Fistory!\n",
      "89 The Magic Realism of Revolutionary Girl Utena\n",
      "185 Religion and Anime!\n",
      "127 The Gay Horror Manga You should Be Reading - The Summer Hikaru Died #horrorstories #manga\n",
      "3421 Heartstopper and Queer Optimism\n",
      "2510 Harry Potter and The Closet Under The Stairs - Queer themes in Harry Potter (Video essay)\n",
      "4445 The Queer Joy of Everything Everywhere All At Once\n",
      "889 Geek Movie Review! Captain America: The Winter Solider\n",
      "150 The Barbie to Evangelion Pipeline\n",
      "1363 Days of Marvel Future - Geek Theory Episode 3\n",
      "2471 The Stonewall Film Effect - Gay Geek Theory (Video essay)\n",
      "23 Killing Stalking and the Love of a Bad Boy\n",
      "280 PSA: Taking A Break From Marvel Movies\n",
      "1383 Geek Theory #4: The Fantastic Five!\n",
      "4755 Disney's Silence on Gay Youth\n",
      "1024 Geek Theory - Episode #1 \"The Marvel Issue\"\n",
      "818 Geek Theory - Episode #2 \"The DC Cinematic Black Hole\"\n",
      "1280 Film Theory #1: Is The Blockbuster Dying?\n",
      "3 Video Games and the Choice to be Gay\n"
     ]
    }
   ],
   "source": [
    "int_words_total = 0\n",
    "for str_key_id in dict_transcripts_two.keys():\n",
    "    #dict_transcripts_two[str_key_id][\"word_count\"] = len(dict_transcripts_two[str_key_id][\"transcript\"].split())\n",
    "    #print(dict_transcripts_two[str_key_id][\"word_count\"])\n",
    "    count = dict_transcripts_two[str_key_id][\"word_count\"]\n",
    "    if count < 5000:\n",
    "        print(count, dict_transcripts_two[str_key_id][\"title\"])\n",
    "    int_words_total += dict_transcripts_two[str_key_id][\"word_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 The Brilliance of Our Flag Means Death\n",
      "201 The Secret Crimes of a Dying Franchise\n",
      "221 The Gay Horror Manga You Should Be Reading\n",
      "531 The Tragedy of Being Rich | James Somerton\n",
      "327 The Dangers of Blissful Ignorance\n",
      "345 The Real Hogwarts Legacy\n",
      "231 How Hollywood was Born Gay\n",
      "497 The Sadism of Class\n",
      "382 For The Love of Gay Nuance\n",
      "290 Disney's War Against Gay kids | James Somerton\n",
      "590 SHIPPING - The Good, The Bad, and the Thirsty\n",
      "491 How Wanda Became An Accidental Gay Icon\n",
      "500 The Gay Appeal of Toxic Love\n",
      "390 Hollywood's (Gay) China Problem | James Somerton\n",
      "318 The Queer Dystopia of the LGB Movement\n",
      "551 An Over-Emotional Look at Why JK Rowling is Bad\n",
      "330 Disney's Gay Cultural Appropriation | James Somerton\n",
      "12 Why Bad Gays Are Good\n",
      "480 The Necessity of Gay Crime | James Somerton\n",
      "183 Heartstopper and Queer Optimism\n",
      "371 The Diversity of \"The Rings of Power\"\n",
      "233 Disney's Silence on Gay Youth\n",
      "27 Making It Big: The History of Gay Adult Film (Documentary)\n"
     ]
    }
   ],
   "source": [
    "int_sentence_total = 0\n",
    "for str_key_id in dict_transcripts_two.keys():\n",
    "    dict_transcripts_two[str_key_id][\"sentence_count\"] = len(dict_transcripts_two[str_key_id][\"transcript\"].split(\".\"))\n",
    "    #print(dict_transcripts_two[str_key_id][\"word_count\"])\n",
    "    count = dict_transcripts_two[str_key_id][\"sentence_count\"]\n",
    "    if count > 10:\n",
    "        print(count, dict_transcripts_two[str_key_id][\"title\"])\n",
    "    int_sentence_total += dict_transcripts_two[str_key_id][\"sentence_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 The Brilliance of Our Flag Means Death\n",
      "201 The Secret Crimes of a Dying Franchise\n",
      "221 The Gay Horror Manga You Should Be Reading\n",
      "531 The Tragedy of Being Rich | James Somerton\n",
      "327 The Dangers of Blissful Ignorance\n",
      "345 The Real Hogwarts Legacy\n",
      "231 How Hollywood was Born Gay\n",
      "497 The Sadism of Class\n",
      "382 For The Love of Gay Nuance\n",
      "290 Disney's War Against Gay kids | James Somerton\n",
      "590 SHIPPING - The Good, The Bad, and the Thirsty\n",
      "491 How Wanda Became An Accidental Gay Icon\n",
      "500 The Gay Appeal of Toxic Love\n",
      "390 Hollywood's (Gay) China Problem | James Somerton\n",
      "318 The Queer Dystopia of the LGB Movement\n",
      "551 An Over-Emotional Look at Why JK Rowling is Bad\n",
      "330 Disney's Gay Cultural Appropriation | James Somerton\n",
      "12 Why Bad Gays Are Good\n",
      "480 The Necessity of Gay Crime | James Somerton\n",
      "183 Heartstopper and Queer Optimism\n",
      "371 The Diversity of \"The Rings of Power\"\n",
      "233 Disney's Silence on Gay Youth\n",
      "27 Making It Big: The History of Gay Adult Film (Documentary)\n"
     ]
    }
   ],
   "source": [
    "int_sentence_total = 0\n",
    "for str_key_id in dict_transcripts_two.keys():\n",
    "    dict_transcripts_two[str_key_id][\"sentence_count\"] = len(dict_transcripts_two[str_key_id][\"transcript\"].split(\".\"))\n",
    "    #print(dict_transcripts_two[str_key_id][\"word_count\"])\n",
    "    count = dict_transcripts_two[str_key_id][\"sentence_count\"]\n",
    "    if count > 10:\n",
    "        print(count, dict_transcripts_two[str_key_id][\"title\"])\n",
    "    int_sentence_total += dict_transcripts_two[str_key_id][\"sentence_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509802"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_words_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8110"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_sentence_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Column Options\n",
    "new_names = ['list of new names in exact order']\n",
    "new_names = {'old_name': 'new_name'}\n",
    "df.columns = new_names\n",
    "\n",
    "df.rename({\n",
    "    'Old Name' : 'New_name'\n",
    "}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[''].fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['column'] <>!= something\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([], axis = 1)#inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_funct(cell):\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[''] = df[''].map(lambda x:)#map_funct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#org_qualitative_col  = df['org_qualitative_col']\n",
    "df = pd.get_dummies(df)\n",
    "#df['org_qualitative_col'] = org_qualitative_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language Processing libraries, initiations and functions\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import re # Delete this if scraping in same notebook\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-zA-Z]',' ', text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    return \" \".join([lemmer.lemmatize(word) for word \n",
    "                     in tokens if len(word) > 1 and not word in stop_words])\n",
    "cvec = CountVectorizer(analyzer = \"word\",\n",
    "                       min_df = 2,\n",
    "                       preprocessor = preprocess,\n",
    "                       stop_words = 'english')\n",
    "#pd.DataFrame(cvec.fit_transform(df['COLUMN']).todense(), columns=cvec.get_feature_names())\n",
    "\n",
    "def LDA(input_item, num_topics = 3, num_words = 5, pre_cveced = False):\n",
    "    # Cols are the words. Rows are the topics\n",
    "    topic_lists = []\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, learning_method='online')\n",
    "    \n",
    "    if  pre_cveced == False: # For inserting a column and automatically cvecing things in function.\n",
    "        lda.fit(cvec.fit_transform(input_item))\n",
    "    elif pre_cveced == True: # For inserting a pre-cveced dataframe.\n",
    "        lda.fit(input_item)\n",
    "    else:\n",
    "        print(\"Not good pre_cveced option given.\")\n",
    "    for ix, topic in enumerate(lda.components_):\n",
    "        topic_lists += [[cvec.get_feature_names()[i] for i \n",
    "                         in lda.components_[ix].argsort()[:-num_words - 1:-1]]]\n",
    "\n",
    "    return pd.DataFrame(topic_lists, columns=[ 'word_' + str(i) for i \n",
    "                                    in range(1, num_words+1)], index=range(1, num_topics + 1)) \n",
    "\n",
    "\n",
    "def Sentamentize(text):\n",
    "    return TextBlob(str(text)).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.dtypes# Return column data types\n",
    "df.describe() #(returns count, mean, std, min, and %iles)???\n",
    "df.info()\n",
    "df['col1'].std() # Standard Deviation\n",
    "\n",
    "\n",
    "# Main ways to adjust indexes\n",
    "df.reset_index(inplace=True)\n",
    "df.set_index('column', inplace = True)\n",
    "df = df.reindex(['cols'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# Concat\n",
    "the_dfs = [df_one,df_two]\n",
    "df_main = pd.concat(the_dfs, sort=False, axis = 1)\n",
    "\n",
    "# Dropping columns with \"Errors\"\n",
    "mask = df['col'] == 'Error'\n",
    "df.drop(df[mask].index, inplace = True)\n",
    "\n",
    "# Dropping Duplicates\n",
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "# Map Function Starter\n",
    "def map_funct(cell):\n",
    "    return cell\n",
    "df['column'] = df['column'].map(lambda x: map_funct(x))\n",
    "\n",
    "\n",
    "# Masks\n",
    "mask = df['column'] <=> something \n",
    "df = df[mask]\n",
    "\n",
    "df[~mask] (Select opposite of the mask)\n",
    "df[(df['col1'] > num) & (df['col2'] < num)]\n",
    "df[(df['col1'] > num) | (df['col2'] > num)]\n",
    "df[ df['col'].isin([num, num]) ] #return rows with specific values(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA\n",
    "\n",
    "df.dtypes                           # Data Types of cols\n",
    "df.column.unique()                  # Unique Values in col\n",
    "df.describe().T                     # Summary Stats\n",
    "df.info                             # Info\n",
    "df['column'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "| Thing             | Main Matplotlib               | Sub Plt               | Seaborn                           |\n",
    "|-------------------|-------------------------------|-----------------------|-----------------------------------|\n",
    "| Idea              | + to plt each line            |fig, ax = plt.subplots(ncols, nrows) (ax[#,#] for ea plt)| |\n",
    "| Bar               | plt.bar(x, height)            |                       |                                   |\n",
    "| Histagram         | plt.hist(x, bins)(Lists Args) |                       |                                   |\n",
    "| Scatter           | plt.scatter(x, y)    (Args)   |                       |                                   |\n",
    "| Line Graph        | plt.plot([y's_ea_x(#,#)(#,])  | ax[#]plot()           | sns.lineplot(x,y)(Args)           |\n",
    "| FacetGrid (Chi2)  |                               |                       | sns.FacetGrid(df, col, row)       |\n",
    "| ...define inr plts|                               |                       |.map(plt.graph, bins, range)       |\n",
    "| X/Y Labels        | plt.zlabel(\"\")                | ax[#].set_xlabel()    |                                   |\n",
    "| Title             | plt.title(\"\")                 | ax[#].set_title()     |                                   |\n",
    "| Figure Size       | plt.figure(figsize)           | plt.subplots(figsize) |                                   |\n",
    "|Customize X/Y Ticks| plt.zticks([labels], rotation)|\n",
    "| Add a Line        | plt.axvline(x)                |\n",
    "| Set Z Value Limit | plt.gca().set_zlim([#,#])     |\n",
    "| Add Legend        | plt.legend()                  |\n",
    "\n",
    "\n",
    "The six \"lessons\" of visualizing data.\n",
    " - Lesson 1: Understand the context. (Who, What, How)\n",
    " - Lesson 2: Choose an appropriate visual display. (What type of graph?)\n",
    " - Lesson 3: Eliminate clutter. (What can I delete or make more subtle?)\n",
    " - Lesson 4: Focus attention where you want it. (How do I emphasize important things?)\n",
    " - Lesson 5: Think like a designer. (How do I organize my visualization?)\n",
    " - Lesson 6: Tell a story! (How do I communicate my visualization?)\n",
    "\n",
    "\n",
    "-------------------------------------------\n",
    "\n",
    "## Set Up Options\n",
    "\n",
    "# import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Color Options\n",
    "colors = {'blue': '#729ECE',\n",
    "          'brown': '#A8786E',\n",
    "          'green': '#67BF5C',\n",
    "          'grey': '#A2A2A2',\n",
    "          'orange': '#FF9E4A',\n",
    "          'pink': '#ED97CA',\n",
    "          'purple': '#AD8BC9',\n",
    "          'red': '#ED665D',\n",
    "          'teal': '#6DCCDA',\n",
    "          'yellow': '#CDCC5D'}\n",
    "\n",
    "# Style Options\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "# Basic Non-Visual EDA\n",
    "\n",
    "df.dtypes                           # Data Types of cols\n",
    "df.column.unique()                  # Unique Values in col\n",
    "df.describe().T                     # Summary Stats\n",
    "df.info                             # Info\n",
    "df['column'].value_counts(normalize=True)\n",
    "\n",
    "# Correlations between two seperate columns w/o a whole thing\n",
    "print(np.corrcoef(df['column_1'].values, df['column_2'].values))\n",
    "\n",
    "# SCATTER\n",
    "\n",
    "\n",
    "## PLT\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(y = df['column_one'],\n",
    "            x = df['column_two'],\n",
    "            color = colors);\n",
    "\n",
    "## PD\n",
    "df.plot('math', 'num_awards', kind = 'scatter')\n",
    "\n",
    "\n",
    "## SNS Dirty\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1,35])\n",
    "axes.set_ylim([-1,35])\n",
    "sns.scatterplot(df['column_one'], df['column_two'], hue= df['column_three'], alpha = 0.1);\n",
    "\n",
    "# BOXPLOT\n",
    "\n",
    "## SNS\n",
    "sns.boxplot(df['column'],\n",
    "            data = df\n",
    "                orient='v' or 'h',\n",
    "                fliersize=8,\n",
    "                linewidth=#,\n",
    "                notch = True,\n",
    "                saturation=0.5,\n",
    "                ax=ax,\n",
    "                by = \"column?\");\n",
    "\n",
    "# LINEPLOT\n",
    "\n",
    "sns.lineplot(data = df);\n",
    "\n",
    "====================================================\n",
    "# HISTAGRAM\n",
    "\n",
    "## PLT\n",
    "plt.hist(df['column'], bins = 10, color='g', alpha = 0.1);\n",
    "plt.xlabel(\"Label\", position = (0,0), ha = 'left', color = 'grey') # (x,y)\n",
    "plt.ylabel(\"label\", position = (0, 1), ha = 'right', color = 'grey'); # (x,y);\n",
    "\n",
    "## PLT.plot\n",
    "figure, ax = plt.subplots(nrows = 2, ncols = 1, figsize = (15,15))\n",
    "test_df['column_one'].plot(ax = ax[0], kind = 'hist')\n",
    "test_df['column_two'].plot(ax = ax[1], kind = 'hist');\n",
    "\n",
    "## PD\n",
    "df.plot(x='col1', y='col2', title=\"Title\")\n",
    "df.hist('col');\n",
    "\n",
    "## SNS Countplot\n",
    "sns.countplot(raw_df['col']);\n",
    "##Also\n",
    "sns.countplot(x=\"col\", data=df);\n",
    "\n",
    "------------\n",
    "# Other Example DIRTY\n",
    "plt.hist(df['col1'],bins= len(df['col1'].unique()));\n",
    "\n",
    "\n",
    "====================================================\n",
    "# BARPLOT\n",
    "\n",
    "## PLT\n",
    "plt.figure(figsize = (16,6))\n",
    "plt.bar(height = df['Column?'],  # List of numbers?\n",
    "        x = df.columns);\n",
    "\n",
    "## SNS\n",
    "sns.barplot(data = df,\n",
    "            x = \"column_one\",\n",
    "            y = \"column_two\");\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "====================================================\n",
    "# PAIRPLOT\n",
    "\n",
    "sns.pairplot(df, kind = \"reg\", \n",
    "             hue = 'column',\n",
    "             plot_kws = {'line_kws' : {'color' : 'red'}, \n",
    "                         'scatter_kws' : {'alpha' : 0.1}})\n",
    "             # Alt\n",
    "             # plot_kws={'alpha': 0.05});\n",
    "\n",
    "# With specific rows, only\n",
    "sns.pairplot(data=temp_df,\n",
    "            x_vars=['col1'],\n",
    "            y_vars=['col2'])\n",
    "\n",
    "\n",
    "====================================================\n",
    "# HEATMAP\n",
    "\n",
    "# SNS\n",
    "#plt.figure(figsize= (9,9))\n",
    "sns.heatmap(df.corr(), \n",
    "            cbar=False, \n",
    "            linewidths= .01, \n",
    "            linecolor='black', \n",
    "            cmap=sns.color_palette(\"Purples\"),\n",
    "            annot=True);\n",
    "\n",
    "\n",
    "=======================================================\n",
    "# Jointplot\n",
    "sns.jointplot(y_test, lin_reg.predict(X_test))\n",
    "\n",
    "=======================================================\n",
    "# Facet Grid\n",
    "Grid = sns.FacetGrid(df, col=\"Col1\", row=\"col2\", margin_titles=True)\n",
    "Grid.map(plt.hist,'col2?', bins = num, range = (num,num));\n",
    "\n",
    "=======================================================\n",
    "# Graph Alterations\n",
    "# Colors: plt.colors.cnames\n",
    "\n",
    "# For layering on top:\n",
    "plt.hist(df['column_1'], color='g')\n",
    "plt.hist(df['column_2'], color='b')\n",
    "\n",
    "# For layering next to:\n",
    "fig, ax = plt.subplots(2, \n",
    "                    sharex = True,  # Scale x together\n",
    "                    sharey = True,    \n",
    "                   figsize = (1,1)) # Size\n",
    "ax[0].hist(df['column_1'],          # \n",
    "           bins = 10,               # Bins\n",
    "           color='b',               # Color\n",
    "           alpha = 0.5,             # Transparancy\n",
    "           label = 'col_1')         # For .legend()\n",
    "ax[1].hist(df['column_2'])          # \n",
    "\n",
    "# Subplot Example\n",
    "\n",
    "fig, axes = plt.subplots(3, figsize = (20,10))\n",
    "sns.countplot(df['col'], ax= axes[0])\n",
    "sns.countplot(df['col'], ax = axes[1])\n",
    "sns.countplot(df['col'], ax = axes[2]);\n",
    "\n",
    "# Labels for Words\n",
    "plt.xlabel(\"measure\",               # Alt: .ylabel\n",
    "           position = (0,0),        # (x-pos, y-pos)?\n",
    "           ha = 'left',             # Horizontal\n",
    "           color = 'grey') # (x,y)\n",
    "\n",
    "plt.legend()\n",
    "plt.title()                         # Title ~= Subtitle\n",
    "plt.suptitle(\"subtitle\\n.\",         # Subtitle\n",
    "             position = (0,1),      # Position\n",
    "             ha = 'left',           # Horizontal\n",
    "             fontsize=16,           # Size, Font\n",
    "             va = 'top');           # Vertical\n",
    "\n",
    "\n",
    "# Shifting Graph Coordinates (in a Scatter plot)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([num_one,num_two])\n",
    "axes.set_ylim([num_one,num_two])\n",
    "sns.scatterplot(df['column_one'], df['column_two']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
